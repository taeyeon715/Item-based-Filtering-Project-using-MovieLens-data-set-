{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Z-Score Normalization\n",
        "\n",
        "[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "태그 데이터 로드 및 전처리 완료\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel # 필요한 라이브러리 임포트\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # 태그 벡터화 라이브러리 임포트\n",
        "\n",
        "DATA_PATH = './data'\n",
        "ratings = pd.read_csv(f'{DATA_PATH}/ratings.csv')\n",
        "movies  = pd.read_csv(f'{DATA_PATH}/movies.csv')\n",
        "\n",
        "SEED_LIST = [10, 21, 35, 42, 57]\n",
        "PERSONA_HEAVY_USER = 414\n",
        "PERSONA_GENRE_SPECIALIST = 85\n",
        "\n",
        "# [Tag Preprocessing]\n",
        "tags_df = pd.read_csv(f'{DATA_PATH}/tags.csv')\n",
        "tags_df['tag'] = tags_df['tag'].astype(str).str.lower()\n",
        "movie_tags_series = tags_df.groupby('movieId')['tag'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "print(\"태그 데이터 로드 및 전처리 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9d78b74e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_genre_similarity(movies_df):\n",
        "    \"\"\" movies DataFrame을 사용하여 영화 간 장르 코사인 유사도 행렬을 계산합니다. \"\"\"\n",
        "    movies_df = movies_df.copy()\n",
        "    movies_df['genres_list'] = movies_df['genres'].apply(lambda x: x.split('|'))\n",
        "    \n",
        "    mlb = MultiLabelBinarizer()\n",
        "    genre_matrix = pd.DataFrame(mlb.fit_transform(movies_df['genres_list']),\n",
        "                                columns=mlb.classes_,\n",
        "                                index=movies_df['movieId'])\n",
        "    \n",
        "    if '(no genres listed)' in genre_matrix.columns:\n",
        "        genre_matrix = genre_matrix.drop(columns=['(no genres listed)'])\n",
        "\n",
        "    # 코사인 유사도 = 정규화된 Dot Product\n",
        "    S_genre_array = cosine_similarity(genre_matrix.values)\n",
        "    \n",
        "    S_genre_df = pd.DataFrame(S_genre_array, \n",
        "                              index=genre_matrix.index, \n",
        "                              columns=genre_matrix.index)\n",
        "    \n",
        "    np.fill_diagonal(S_genre_df.values, 0.0)\n",
        "    \n",
        "    return S_genre_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 전처리 함수 (Z-Score + 최소 평점 필터링)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_preprocessing(train_df, test_df):\n",
        "    train = train_df.copy()\n",
        "    test  = test_df.copy()\n",
        "\n",
        "    # 1. 최소 5회 이상 평점 준 사용자만 사용 (페르소나는 강제 포함)\n",
        "    user_counts = train['userId'].value_counts()\n",
        "    valid_users = set(user_counts[user_counts >= 5].index)\n",
        "    valid_users = valid_users.union({PERSONA_HEAVY_USER, PERSONA_GENRE_SPECIALIST})\n",
        "\n",
        "    train = train[train['userId'].isin(valid_users)]\n",
        "    test  = test[test['userId'].isin(valid_users)]\n",
        "\n",
        "    # 2. Train에서만 사용자별 mean / std 계산\n",
        "    user_stats = train.groupby('userId')['rating'].agg(['mean', 'std']).fillna(1.0)\n",
        "    user_stats['std'] = user_stats['std'].replace(0, 1.0)   # std=0 방지\n",
        "\n",
        "    # 3. Z-Score 변환 (Train)\n",
        "    train = train.merge(user_stats, on='userId', suffixes=('', '_user'))\n",
        "    train['z_rating'] = (train['rating'] - train['mean']) / train['std']\n",
        "\n",
        "    # 4. Test도 동일한 통계량으로 변환 (Train에 없는 사용자는 제거 → cold-start 방지)\n",
        "    test = test.merge(user_stats, on='userId', how='left')\n",
        "    test = test.dropna(subset=['mean', 'std'])   # Train에 없는 사용자 제거\n",
        "    test['z_rating'] = (test['rating'] - test['mean']) / test['std']\n",
        "\n",
        "    return train, test, user_stats   # user_stats도 반환 (역변환에 필요)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 평가 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cd65a997",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def fast_predict_matrix_no_k(train_df):\n",
        "    \"\"\"\n",
        "    K 제한 없이, 유사도가 양수인 모든 아이템을 사용하여 예측\n",
        "    \"\"\"\n",
        "    # 1. Pivot Table 생성 및 R 행렬 정의\n",
        "    pivot_df = train_df.pivot(index='userId', columns='movieId', values='z_rating').fillna(0)\n",
        "    R = pivot_df.values  # (Users, Items)\n",
        "    user_ids = pivot_df.index\n",
        "    movie_ids = pivot_df.columns\n",
        "    \n",
        "    # 2. 아이템 간 유사도 행렬 계산\n",
        "    sim_matrix = np.dot(R.T, R)\n",
        "    np.fill_diagonal(sim_matrix, -np.inf)\n",
        "    \n",
        "    # 3. [핵심 변경] Top-K 필터링 로직 삭제! 양수 유사도만 남김\n",
        "    S = np.where(sim_matrix > 0, sim_matrix, 0)\n",
        "\n",
        "    # 4. 예측 평점 계산 (Weighted Sum) -> 분자\n",
        "    numerator = np.dot(R, S)\n",
        "    \n",
        "    # 5. 가중치 합 계산 (Sum of Weights) -> 분모\n",
        "    R_binary = (R != 0).astype(float)\n",
        "    denominator = np.dot(R_binary, np.abs(S))\n",
        "    \n",
        "    # 6. 나눗셈 (0으로 나누기 방지)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        pred_z = numerator / denominator\n",
        "        pred_z = np.nan_to_num(pred_z)\n",
        "        \n",
        "    return pred_z, user_ids, movie_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "62683614",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fast_predict_matrix_triple_hybrid(train_df, S_genre_df, movie_tags_series, alpha=0.8, beta=0.1):\n",
        "    \"\"\"\n",
        "    평점(Rating), 장르(Genre), 태그(Tag) 3가지 유사도를 결합한 하이브리드 예측.\n",
        "    S_final = alpha * S_rating_norm + beta * S_genre + (1 - alpha - beta) * S_tag\n",
        "    \"\"\"\n",
        "    # 1. Pivot Table 및 R 행렬 정의\n",
        "    pivot_df = train_df.pivot(index='userId', columns='movieId', values='z_rating').fillna(0)\n",
        "    R = pivot_df.values\n",
        "    user_ids = pivot_df.index\n",
        "    movie_ids = pivot_df.columns\n",
        "    gamma = 1 - alpha - beta # 태그 가중치 (나머지)\n",
        "    \n",
        "    # -------------------------------------------------------\n",
        "    # [A] 평점 기반 유사도 (S_rating)\n",
        "    # -------------------------------------------------------\n",
        "    sim_rating = np.dot(R.T, R)\n",
        "    max_rating = np.max(np.abs(sim_rating)) if np.max(np.abs(sim_rating)) > 0 else 1.0\n",
        "    S_rating_norm = sim_rating / max_rating # -1 ~ 1 사이 정규화\n",
        "    \n",
        "    # -------------------------------------------------------\n",
        "    # [B] 장르 유사도 (S_genre) - Alignment\n",
        "    # -------------------------------------------------------\n",
        "    S_genre_aligned = S_genre_df.loc[movie_ids, movie_ids].values\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # [C] 태그 유사도 (S_tag) - Recalculation & Alignment (최적 max_features 500 사용)\n",
        "    # -------------------------------------------------------\n",
        "    current_movie_tags = [movie_tags_series.get(mid, \"\") for mid in movie_ids]\n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=500) \n",
        "    tfidf_matrix = tfidf.fit_transform(current_movie_tags)\n",
        "    S_tag = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # [D] 3중 유사도 결합 (Triple Hybrid Fusion)\n",
        "    # -------------------------------------------------------\n",
        "    sim_final = alpha * S_rating_norm + beta * S_genre_aligned + gamma * S_tag\n",
        "    \n",
        "    # 자기 자신과의 유사도 제거 및 양수 필터링\n",
        "    np.fill_diagonal(sim_final, -np.inf)\n",
        "    S = np.where(sim_final > 0, sim_final, 0)\n",
        "\n",
        "    # 5. 예측 계산 (Weighted Sum)\n",
        "    numerator = np.dot(R, S)\n",
        "    R_binary = (R != 0).astype(float)\n",
        "    denominator = np.dot(R_binary, np.abs(S))\n",
        "    \n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        pred_z = numerator / denominator\n",
        "        pred_z = np.nan_to_num(pred_z)\n",
        "        \n",
        "    return pred_z, user_ids, movie_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1fbc32fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel # Dot Product와 동일\n",
        "\n",
        "def fast_predict_matrix_with_tags(train_df, movie_tags_series, tag_weight=0.15):\n",
        "    \"\"\"\n",
        "    평점 기반 CF와 태그 기반 Content-based Filtering을 결합한 하이브리드 예측\n",
        "    \n",
        "    Args:\n",
        "        tag_weight (float): 태그 유사도의 반영 비율 (0.0 ~ 1.0)\n",
        "                            0.0이면 순수 CF, 1.0이면 순수 태그 추천\n",
        "    \"\"\"\n",
        "    # 1. Pivot Table 생성 및 R 행렬 정의 (Z-Score)\n",
        "    pivot_df = train_df.pivot(index='userId', columns='movieId', values='z_rating').fillna(0)\n",
        "    R = pivot_df.values\n",
        "    user_ids = pivot_df.index\n",
        "    movie_ids = pivot_df.columns # 현재 Train 셋에 존재하는 영화 ID 순서\n",
        "    \n",
        "    # -------------------------------------------------------\n",
        "    # [A] 평점 기반 유사도 (Collaborative Filtering) - Dot Product\n",
        "    # -------------------------------------------------------\n",
        "    sim_cf = np.dot(R.T, R)\n",
        "    \n",
        "    # -------------------------------------------------------\n",
        "    # [B] 태그 기반 유사도 (Content-Based) - Dot Product (Linear Kernel)\n",
        "    # -------------------------------------------------------\n",
        "    # 1. 현재 Train에 있는 영화 순서대로 태그 데이터 정렬 (없으면 빈 문자열)\n",
        "    current_movie_tags = [movie_tags_series.get(mid, \"\") for mid in movie_ids]\n",
        "    \n",
        "    # 2. TF-IDF 벡터화\n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=500)\n",
        "    tfidf_matrix = tfidf.fit_transform(current_movie_tags)\n",
        "    \n",
        "    # 3. 태그 유사도 계산 (Dot Product)\n",
        "    # TF-IDF 벡터는 정규화되어 있으므로 Dot Product는 코사인 유사도와 같음\n",
        "    sim_tags = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "    \n",
        "    # -------------------------------------------------------\n",
        "    # [C] 유사도 결합 (Hybrid) & 스케일 맞추기\n",
        "    # -------------------------------------------------------\n",
        "    # 평점 유사도(sim_cf)는 값이 크고(예: 수백), 태그 유사도(sim_tags)는 작음(0~1)\n",
        "    # 따라서 sim_cf를 최대값으로 나누어 -1 ~ 1 사이로 정규화한 뒤 결합\n",
        "    \n",
        "    max_cf = np.max(np.abs(sim_cf)) if np.max(np.abs(sim_cf)) > 0 else 1.0\n",
        "    sim_cf_norm = sim_cf / max_cf \n",
        "    \n",
        "    # 하이브리드 유사도 계산\n",
        "    # (1 - tag_weight) * 평점유사도 + (tag_weight) * 태그유사도\n",
        "    sim_hybrid = (1 - tag_weight) * sim_cf_norm + (tag_weight) * sim_tags\n",
        "    \n",
        "    # 자기 자신과의 유사도 제거\n",
        "    np.fill_diagonal(sim_hybrid, -np.inf)\n",
        "    \n",
        "    # 4. 양수 유사도만 남김 (K 제한 없음)\n",
        "    S = np.where(sim_hybrid > 0, sim_hybrid, 0)\n",
        "\n",
        "    # 5. 예측 평점 계산 (Weighted Sum)\n",
        "    numerator = np.dot(R, S)\n",
        "    \n",
        "    R_binary = (R != 0).astype(float)\n",
        "    denominator = np.dot(R_binary, np.abs(S))\n",
        "    \n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        pred_z = numerator / denominator\n",
        "        pred_z = np.nan_to_num(pred_z)\n",
        "        \n",
        "    return pred_z, user_ids, movie_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rmse(y_true, y_pred): return np.sqrt(np.mean((np.array(y_true)-np.array(y_pred))**2))\n",
        "def mae(y_true, y_pred):  return np.mean(np.abs(np.array(y_true)-np.array(y_pred)))\n",
        "\n",
        "def time_predictions(fn, pairs):\n",
        "    s = time.perf_counter()\n",
        "    preds = [fn(u,i) for u,i in pairs]\n",
        "    e = time.perf_counter() - s\n",
        "    return preds, e, (e/len(pairs))*1000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74c149da",
      "metadata": {},
      "source": [
        "# 최적 파라미터 찾기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "68668fa7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Grid Search 시작 (고정 시드 42 사용) ===\n",
            "\n",
            "--- Testing: R_w=0.70, G_w=0.05, T_w=0.25 ---\n",
            "   -> RMSE: 0.8943 | Time: 15.91s\n",
            "\n",
            "--- Testing: R_w=0.70, G_w=0.10, T_w=0.20 ---\n",
            "   -> RMSE: 0.9057 | Time: 11.77s\n",
            "\n",
            "--- Testing: R_w=0.70, G_w=0.15, T_w=0.15 ---\n",
            "   -> RMSE: 0.9115 | Time: 14.40s\n",
            "\n",
            "--- Testing: R_w=0.80, G_w=0.05, T_w=0.15 ---\n",
            "   -> RMSE: 0.8925 | Time: 13.98s\n",
            "\n",
            "--- Testing: R_w=0.80, G_w=0.10, T_w=0.10 ---\n",
            "   -> RMSE: 0.9045 | Time: 12.75s\n",
            "\n",
            "--- Testing: R_w=0.80, G_w=0.15, T_w=0.05 ---\n",
            "   -> RMSE: 0.9107 | Time: 17.42s\n",
            "\n",
            "--- Testing: R_w=0.90, G_w=0.05, T_w=0.05 ---\n",
            "   -> RMSE: 0.8913 | Time: 15.52s\n",
            "\n",
            "=== Grid Search 결과 (RMSE 기준 상위 5개) ===\n",
            "   alpha  beta  gamma      rmse\n",
            "6    0.9  0.05   0.05  0.891335\n",
            "3    0.8  0.05   0.15  0.892505\n",
            "0    0.7  0.05   0.25  0.894296\n",
            "4    0.8  0.10   0.10  0.904493\n",
            "1    0.7  0.10   0.20  0.905660\n",
            "\n",
            "--- Best Combination ---\n",
            "Alpha (평점): 0.9\n",
            "Beta (장르): 0.05\n",
            "Gamma (태그): 0.05\n",
            "Best RMSE: 0.8913\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# [Grid Search] 최적의 α (평점), β (장르), γ (태그) 가중치 찾기\n",
        "# ==========================================\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# 1. 테스트할 파라미터 후보군 정의\n",
        "# α (평점 가중치): CF가 중요하므로 높게 시작\n",
        "ALPHA_LIST = [0.7, 0.8, 0.9]\n",
        "# β (장르 가중치): 0.05 ~ 0.15 사이를 탐색\n",
        "BETA_LIST = [0.05, 0.1, 0.15] \n",
        "\n",
        "# 결과 저장용\n",
        "grid_results = []\n",
        "\n",
        "# 2. 필수 데이터/함수 초기화 (Grid Search 루프 밖에서 1회 실행)\n",
        "# 주의: calculate_genre_similarity 함수와 movie_tags_series는 이전에 정의/로드되어 있어야 합니다.\n",
        "FIXED_SEED = 42 # 일관된 비교를 위해 고정 시드 사용\n",
        "S_genre_df = calculate_genre_similarity(movies.copy()) \n",
        "\n",
        "train_raw, test_raw = train_test_split(ratings, test_size=0.2, random_state=FIXED_SEED)\n",
        "train, test, user_stats = run_preprocessing(train_raw, test_raw)\n",
        "\n",
        "print(\"=== Grid Search 시작 (고정 시드 42 사용) ===\")\n",
        "\n",
        "# 예측 및 평가를 위한 기본 설정\n",
        "pivot_temp = train.pivot(index='userId', columns='movieId', values='z_rating').fillna(0)\n",
        "u_map = {u: i for i, u in enumerate(pivot_temp.index)}\n",
        "m_map = {m: i for i, m in enumerate(pivot_temp.columns)}\n",
        "\n",
        "rng = np.random.default_rng(FIXED_SEED)\n",
        "test_sample = test[['userId', 'movieId', 'rating', 'mean', 'std']].sample(n=min(3000, len(test)), random_state=FIXED_SEED)\n",
        "\n",
        "\n",
        "# 3. 가중치 조합 탐색\n",
        "for ALPHA in ALPHA_LIST:\n",
        "    for BETA in BETA_LIST:\n",
        "        GAMMA = 1 - ALPHA - BETA # 태그 가중치 (1 - α - β)\n",
        "        \n",
        "        # 가중치 합이 1을 초과하거나 음수 가중치가 발생하는 경우 제외\n",
        "        if GAMMA < 0 or GAMMA > 1:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n--- Testing: R_w={ALPHA:.2f}, G_w={BETA:.2f}, T_w={GAMMA:.2f} ---\")\n",
        "        \n",
        "        s = time.perf_counter()\n",
        "        \n",
        "        # [핵심] 3중 하이브리드 예측 함수 호출\n",
        "        pred_matrix_z, u_ids, m_ids = fast_predict_matrix_triple_hybrid(\n",
        "            train, S_genre_df, movie_tags_series, alpha=ALPHA, beta=BETA\n",
        "        )\n",
        "        \n",
        "        e = time.perf_counter() - s\n",
        "        \n",
        "        # 4. 평가 (RMSE 계산)\n",
        "        z_preds = []\n",
        "        y_true = []\n",
        "\n",
        "        for row in test_sample.itertuples():\n",
        "            if row.userId in u_map and row.movieId in m_map:\n",
        "                u_idx = u_map[row.userId]\n",
        "                m_idx = m_map[row.movieId]\n",
        "                pred_z = pred_matrix_z[u_idx, m_idx]\n",
        "                \n",
        "                # 역변환 및 클리핑\n",
        "                raw_score = pred_z * row.std + row.mean\n",
        "                final_score = np.clip(raw_score, 0.5, 5.0) \n",
        "                \n",
        "                z_preds.append(final_score)\n",
        "                y_true.append(row.rating)\n",
        "        \n",
        "        curr_rmse = rmse(y_true, z_preds)\n",
        "        \n",
        "        print(f\"   -> RMSE: {curr_rmse:.4f} | Time: {e:.2f}s\")\n",
        "        \n",
        "        grid_results.append({\n",
        "            'alpha': ALPHA,\n",
        "            'beta': BETA,\n",
        "            'gamma': GAMMA,\n",
        "            'rmse': curr_rmse\n",
        "        })\n",
        "\n",
        "# 5. 최적의 결과 출력\n",
        "df_grid = pd.DataFrame(grid_results)\n",
        "best_row = df_grid.loc[df_grid['rmse'].idxmin()]\n",
        "\n",
        "print(\"\\n=== Grid Search 결과 (RMSE 기준 상위 5개) ===\")\n",
        "print(df_grid.sort_values(by='rmse').head())\n",
        "\n",
        "print(\"\\n--- Best Combination ---\")\n",
        "print(f\"Alpha (평점): {best_row['alpha']}\")\n",
        "print(f\"Beta (장르): {best_row['beta']}\")\n",
        "print(f\"Gamma (태그): {best_row['gamma']:.2f}\")\n",
        "print(f\"Best RMSE: {best_row['rmse']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Multi-seed 실험 루프"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "하이브리드 실험 시작: R_w=0.80, G_w=0.10, T_w=0.10. 총 5개 시드 테스트.\n",
            "\n",
            "Running Seed 10 (1/5)\n",
            " -> RMSE: 0.8825, Time: 16.6319s\n",
            "\n",
            "[추천 결과 생성 중...]\n",
            "\n",
            "Running Seed 21 (2/5)\n",
            " -> RMSE: 0.9014, Time: 11.0486s\n",
            "\n",
            "Running Seed 35 (3/5)\n",
            " -> RMSE: 0.8981, Time: 11.6287s\n",
            "\n",
            "Running Seed 42 (4/5)\n",
            " -> RMSE: 0.9097, Time: 12.2880s\n",
            "\n",
            "Running Seed 57 (5/5)\n",
            " -> RMSE: 0.8719, Time: 14.2329s\n",
            "\n",
            "실험 완료! (결과 요약 셀을 실행하세요)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# [3. Multi-seed 실험 루프 - 3중 하이브리드 버전]\n",
        "# ==========================================\n",
        "\n",
        "results = []\n",
        "best_reco = None\n",
        "\n",
        "# 1. 초기화: 장르 유사도 행렬을 미리 계산\n",
        "S_genre_df = calculate_genre_similarity(movies.copy()) \n",
        "movie_tags_series # 태그 시리즈는 1단계에서 이미 로드됨\n",
        "\n",
        "# 2. 가중치 설정 (CF가 가장 중요하고 태그와 장르를 1:1로 보조)\n",
        "ALPHA = 0.8  # 평점 가중치 (R_w)\n",
        "BETA = 0.1   # 장르 가중치 (G_w)\n",
        "GAMMA = 1 - ALPHA - BETA # 태그 가중치 (T_w) -> 0.1\n",
        "\n",
        "print(f\"하이브리드 실험 시작: R_w={ALPHA:.2f}, G_w={BETA:.2f}, T_w={GAMMA:.2f}. 총 {len(SEED_LIST)}개 시드 테스트.\")\n",
        "\n",
        "for idx, SEED in enumerate(SEED_LIST):\n",
        "    print(f\"\\nRunning Seed {SEED} ({idx+1}/{len(SEED_LIST)})\")\n",
        "\n",
        "    # 1. 데이터 분할 및 전처리\n",
        "    train_raw, test_raw = train_test_split(ratings, test_size=0.2, random_state=SEED)\n",
        "    train, test, user_stats = run_preprocessing(train_raw, test_raw)\n",
        "\n",
        "    # 2. [핵심] 3중 하이브리드 예측 함수 호출\n",
        "    s = time.perf_counter()\n",
        "    pred_matrix_z, u_ids, m_ids = fast_predict_matrix_triple_hybrid(\n",
        "        train, S_genre_df, movie_tags_series, alpha=ALPHA, beta=BETA\n",
        "    )\n",
        "    e = time.perf_counter() - s\n",
        "    \n",
        "    # 인덱싱 맵핑\n",
        "    u_map = {u: i for i, u in enumerate(u_ids)}\n",
        "    m_map = {m: i for i, m in enumerate(m_ids)}\n",
        "\n",
        "    # 3. Test 샘플링 (평가용 데이터 3000개)\n",
        "    rng = np.random.default_rng(SEED)\n",
        "    test_sample = test[['userId', 'movieId', 'rating', 'mean', 'std']].sample(n=min(3000, len(test)), random_state=SEED)\n",
        "\n",
        "    # 4. Test 데이터에 대한 예측값 추출\n",
        "    z_preds = []\n",
        "    for uid, mid in zip(test_sample['userId'], test_sample['movieId']):\n",
        "        if uid in u_map and mid in m_map:\n",
        "            u_idx = u_map[uid]\n",
        "            m_idx = m_map[mid]\n",
        "            z_preds.append(pred_matrix_z[u_idx, m_idx])\n",
        "        else:\n",
        "            z_preds.append(0.0)\n",
        "\n",
        "    # 5. 역변환 (클리핑 적용)\n",
        "    original_preds = []\n",
        "    for pred_z, row in zip(z_preds, test_sample.itertuples()):\n",
        "        mean_u = row.mean\n",
        "        std_u  = row.std\n",
        "        raw_score = pred_z * std_u + mean_u\n",
        "        final_score = np.clip(raw_score, 0.5, 5.0) \n",
        "        original_preds.append(final_score)\n",
        "\n",
        "    # 6. 결과 저장\n",
        "    avg_ms = (e / len(test_sample)) * 1000 \n",
        "    \n",
        "    res = {\n",
        "        'seed': SEED,\n",
        "        'rmse': rmse(test_sample['rating'], original_preds),\n",
        "        'mae' : mae(test_sample['rating'], original_preds),\n",
        "        'avg_ms': avg_ms\n",
        "    }\n",
        "    results.append(res)\n",
        "    print(f\" -> RMSE: {res['rmse']:.4f}, Time: {e:.4f}s\")\n",
        "\n",
        "    # 7. 첫 번째 시드(Seed 10)에서만 추천 결과 생성 \n",
        "    if idx == 0:\n",
        "        def recommend(user_id, topk=3):\n",
        "            if user_id not in u_map: return None\n",
        "            u_idx = u_map[user_id]\n",
        "            user_row_preds = pred_matrix_z[u_idx] \n",
        "            watched = set(train[train['userId']==user_id]['movieId'])\n",
        "            \n",
        "            candidates = []\n",
        "            for m_idx, m_id in enumerate(m_ids):\n",
        "                if m_id in watched: continue\n",
        "                \n",
        "                z = user_row_preds[m_idx]\n",
        "                mean_u = user_stats.loc[user_id, 'mean']\n",
        "                std_u  = user_stats.loc[user_id, 'std']\n",
        "                \n",
        "                raw_score = z * std_u + mean_u\n",
        "                final_score = np.clip(raw_score, 0.5, 5.0) \n",
        "                \n",
        "                candidates.append((m_id, final_score))\n",
        "            \n",
        "            candidates.sort(key=lambda x: -x[1])\n",
        "            top = candidates[:topk]\n",
        "            \n",
        "            return [{\n",
        "                'movieId': m,\n",
        "                'title': movies.loc[movies['movieId']==m, 'title'].iloc[0] if len(movies.loc[movies['movieId']==m]) > 0 else \"Unknown\",\n",
        "                'predicted_rating': round(score, 3)\n",
        "            } for m, score in top]\n",
        "\n",
        "        print(\"\\n[추천 결과 생성 중...]\")\n",
        "        best_reco = {\n",
        "            'heavy': recommend(PERSONA_HEAVY_USER),\n",
        "            'specialist': recommend(PERSONA_GENRE_SPECIALIST)\n",
        "        }\n",
        "\n",
        "print(\"\\n실험 완료! (결과 요약 셀을 실행하세요)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 결과 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   seed    rmse     mae  avg_ms\n",
            "0    10  0.8825  0.6813  5.5440\n",
            "1    21  0.9014  0.6916  3.6829\n",
            "2    35  0.8981  0.6986  3.8762\n",
            "3    42  0.9097  0.7029  4.0960\n",
            "4    57  0.8719  0.6730  4.7443\n",
            "\n",
            "=== 평균 ± 표준편차 ===\n",
            "RMSE : 0.8927 ± 0.0153\n",
            "MAE  : 0.6895 ± 0.0123\n",
            "예측 속도 : 4.39 ms (± 0.76)\n",
            "\n",
            "=== 페르소나 추천 결과 (Seed 10) ===\n",
            "헤비 유저 (userId=414)\n",
            "  → La cravate (1957)  (예측 평점 4.679)\n",
            "  → A Cosmic Christmas (1977)  (예측 평점 4.255)\n",
            "  → The Adventures of Sherlock Holmes and Doctor Watson  (예측 평점 4.241)\n",
            "\n",
            "드라마 전문가 (userId=85)\n",
            "  → Far From Home: The Adventures of Yellow Dog (1995)  (예측 평점 5.0)\n",
            "  → Swan Princess, The (1994)  (예측 평점 5.0)\n",
            "  → Lassie (1994)  (예측 평점 5.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(results)\n",
        "print(df[['seed','rmse','mae','avg_ms']].round(4))\n",
        "print(\"\\n=== 평균 ± 표준편차 ===\")\n",
        "print(f\"RMSE : {df.rmse.mean():.4f} ± {df.rmse.std():.4f}\")\n",
        "print(f\"MAE  : {df.mae.mean():.4f} ± {df.mae.std():.4f}\")\n",
        "print(f\"예측 속도 : {df.avg_ms.mean():.2f} ms (± {df.avg_ms.std():.2f})\")\n",
        "\n",
        "print(\"\\n=== 페르소나 추천 결과 (Seed 10) ===\")\n",
        "print(f\"헤비 유저 (userId={PERSONA_HEAVY_USER})\")\n",
        "for x in best_reco['heavy']:\n",
        "    print(f\"  → {x['title']}  (예측 평점 {x['predicted_rating']})\")\n",
        "\n",
        "print(f\"\\n드라마 전문가 (userId={PERSONA_GENRE_SPECIALIST})\")\n",
        "for x in best_reco['specialist']:\n",
        "    print(f\"  → {x['title']}  (예측 평점 {x['predicted_rating']})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "67fbc37b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Grid Search 시작 ===\n",
            "\n",
            "[Testing] max_features = 500 ...\n",
            "   -> Weight: 0.05 | RMSE: 0.8843 | Time: 5.19s\n",
            "   -> Weight: 0.1 | RMSE: 0.8853 | Time: 8.07s\n",
            "   -> Weight: 0.15 | RMSE: 0.8863 | Time: 7.43s\n",
            "   -> Weight: 0.2 | RMSE: 0.8875 | Time: 6.55s\n",
            "   -> Weight: 0.25 | RMSE: 0.8888 | Time: 8.14s\n",
            "\n",
            "[Testing] max_features = 1000 ...\n",
            "   -> Weight: 0.05 | RMSE: 0.8844 | Time: 10.97s\n",
            "   -> Weight: 0.1 | RMSE: 0.8853 | Time: 12.14s\n",
            "   -> Weight: 0.15 | RMSE: 0.8863 | Time: 9.22s\n",
            "   -> Weight: 0.2 | RMSE: 0.8874 | Time: 11.53s\n",
            "   -> Weight: 0.25 | RMSE: 0.8886 | Time: 9.36s\n",
            "\n",
            "[Testing] max_features = 3000 ...\n",
            "   -> Weight: 0.05 | RMSE: 0.8845 | Time: 9.70s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m S = np.where(sim_hybrid > \u001b[32m0\u001b[39m, sim_hybrid, \u001b[32m0\u001b[39m)\n\u001b[32m     54\u001b[39m num = np.dot(R, S)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m den = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, invalid=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     58\u001b[39m     pred_z = np.nan_to_num(num / den)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# [Grid Search] 최적의 파라미터(태그 가중치, 개수) 찾기\n",
        "# ==========================================\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import time\n",
        "\n",
        "# 1. 테스트할 파라미터 후보군 정의\n",
        "MAX_FEATURES_LIST = [500, 1000, 3000]   # 태그 개수 후보\n",
        "TAG_WEIGHT_LIST   = [0.05, 0.1, 0.15, 0.2, 0.25] # 가중치 후보\n",
        "\n",
        "# 결과 저장용\n",
        "grid_results = []\n",
        "\n",
        "print(\"=== Grid Search 시작 ===\")\n",
        "\n",
        "# Train/Test 데이터는 고정된 시드(예: 42)로 한 번만 나눔 (비교를 위해)\n",
        "FIXED_SEED = 42\n",
        "train_raw, test_raw = train_test_split(ratings, test_size=0.2, random_state=FIXED_SEED)\n",
        "train, test, user_stats = run_preprocessing(train_raw, test_raw)\n",
        "\n",
        "# [A] max_features 루프\n",
        "for n_feat in MAX_FEATURES_LIST:\n",
        "    print(f\"\\n[Testing] max_features = {n_feat} ...\")\n",
        "    \n",
        "    # 1. TF-IDF 및 태그 유사도 계산 (n_feat가 바뀔 때마다 새로 계산)\n",
        "    # 현재 Train에 있는 영화 ID 기준 태그 정렬\n",
        "    pivot_temp = train.pivot(index='userId', columns='movieId', values='z_rating').fillna(0)\n",
        "    movie_ids_temp = pivot_temp.columns\n",
        "    current_movie_tags = [movie_tags_series.get(mid, \"\") for mid in movie_ids_temp]\n",
        "    \n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=n_feat)\n",
        "    tfidf_matrix = tfidf.fit_transform(current_movie_tags)\n",
        "    sim_tags_fixed = linear_kernel(tfidf_matrix, tfidf_matrix) # 미리 계산\n",
        "    \n",
        "    # [B] tag_weight 루프\n",
        "    for weight in TAG_WEIGHT_LIST:\n",
        "        \n",
        "        # --- 예측 로직 (Inline 구현) ---\n",
        "        s_time = time.perf_counter()\n",
        "        \n",
        "        # 평점 유사도\n",
        "        R = pivot_temp.values\n",
        "        sim_cf = np.dot(R.T, R)\n",
        "        max_cf = np.max(np.abs(sim_cf)) if np.max(np.abs(sim_cf)) > 0 else 1.0\n",
        "        sim_cf_norm = sim_cf / max_cf\n",
        "        \n",
        "        # 하이브리드 결합\n",
        "        sim_hybrid = (1 - weight) * sim_cf_norm + (weight) * sim_tags_fixed\n",
        "        np.fill_diagonal(sim_hybrid, -np.inf)\n",
        "        \n",
        "        # 예측 계산\n",
        "        S = np.where(sim_hybrid > 0, sim_hybrid, 0)\n",
        "        num = np.dot(R, S)\n",
        "        den = np.dot((R != 0).astype(float), np.abs(S))\n",
        "        \n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            pred_z = np.nan_to_num(num / den)\n",
        "            \n",
        "        # 평가 (Test Sample 3000개)\n",
        "        rng = np.random.default_rng(FIXED_SEED)\n",
        "        test_sample = test.sample(n=min(3000, len(test)), random_state=FIXED_SEED)\n",
        "        \n",
        "        u_map = {u: i for i, u in enumerate(pivot_temp.index)}\n",
        "        m_map = {m: i for i, m in enumerate(pivot_temp.columns)}\n",
        "        \n",
        "        original_preds = []\n",
        "        y_true = []\n",
        "        \n",
        "        for row in test_sample.itertuples():\n",
        "            if row.userId in u_map and row.movieId in m_map:\n",
        "                u_idx = u_map[row.userId]\n",
        "                m_idx = m_map[row.movieId]\n",
        "                val = pred_z[u_idx, m_idx]\n",
        "                original_preds.append(val * row.std + row.mean)\n",
        "                y_true.append(row.rating)\n",
        "        \n",
        "        curr_rmse = rmse(y_true, original_preds)\n",
        "        e_time = time.perf_counter() - s_time\n",
        "        \n",
        "        print(f\"   -> Weight: {weight} | RMSE: {curr_rmse:.4f} | Time: {e_time:.2f}s\")\n",
        "        \n",
        "        grid_results.append({\n",
        "            'max_features': n_feat,\n",
        "            'tag_weight': weight,\n",
        "            'rmse': curr_rmse\n",
        "        })\n",
        "\n",
        "# 3. 최적의 결과 출력\n",
        "df_grid = pd.DataFrame(grid_results)\n",
        "best_row = df_grid.loc[df_grid['rmse'].idxmin()]\n",
        "\n",
        "print(\"\\n=== 최적의 파라미터 조합 ===\")\n",
        "print(f\"Max Features: {int(best_row['max_features'])}\")\n",
        "print(f\"Tag Weight  : {best_row['tag_weight']}\")\n",
        "print(f\"Best RMSE   : {best_row['rmse']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a81518",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": "MovieLens 100K + Item-based CF + Z-Score (올바르게 적용된 버전)",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
