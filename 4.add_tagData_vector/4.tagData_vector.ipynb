{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Z-Score Normalization\n",
        "\n",
        "[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "태그 데이터 로드 완료: 1572개의 영화에 태그 정보가 있습니다.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DATA_PATH = './data'\n",
        "ratings = pd.read_csv(f'{DATA_PATH}/ratings.csv')\n",
        "movies  = pd.read_csv(f'{DATA_PATH}/movies.csv')\n",
        "\n",
        "#SEED_LIST = [10, 21, 35, 42, 57, 60, 73, 88, 95, 101] -> 5개로 감소소\n",
        "SEED_LIST = [10, 21, 35, 42, 57]\n",
        "PERSONA_HEAVY_USER = 414\n",
        "PERSONA_GENRE_SPECIALIST = 85\n",
        "\n",
        "# [Step 1] 태그 데이터 로드 및 전처리\n",
        "tags_df = pd.read_csv(f'{DATA_PATH}/tags.csv')\n",
        "\n",
        "# 태그 전처리: 소문자 변환 (대소문자 통일)\n",
        "tags_df['tag'] = tags_df['tag'].astype(str).str.lower()\n",
        "\n",
        "# 영화별로 태그를 하나의 문자열로 합치기 (예: \"funny action hero ...\")\n",
        "# 결과: index=movieId, value=\"tag1 tag2 tag3...\"\n",
        "movie_tags_series = tags_df.groupby('movieId')['tag'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "print(f\"태그 데이터 로드 완료: {len(movie_tags_series)}개의 영화에 태그 정보가 있습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 전처리 함수 (Z-Score + 최소 평점 필터링)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_preprocessing(train_df, test_df):\n",
        "    train = train_df.copy()\n",
        "    test  = test_df.copy()\n",
        "\n",
        "    # 1. 최소 5회 이상 평점 준 사용자만 사용 (페르소나는 강제 포함)\n",
        "    user_counts = train['userId'].value_counts()\n",
        "    valid_users = set(user_counts[user_counts >= 5].index)\n",
        "    valid_users = valid_users.union({PERSONA_HEAVY_USER, PERSONA_GENRE_SPECIALIST})\n",
        "\n",
        "    train = train[train['userId'].isin(valid_users)]\n",
        "    test  = test[test['userId'].isin(valid_users)]\n",
        "\n",
        "    # 2. Train에서만 사용자별 mean / std 계산\n",
        "    user_stats = train.groupby('userId')['rating'].agg(['mean', 'std']).fillna(1.0)\n",
        "    user_stats['std'] = user_stats['std'].replace(0, 1.0)   # std=0 방지\n",
        "\n",
        "    # 3. Z-Score 변환 (Train)\n",
        "    train = train.merge(user_stats, on='userId', suffixes=('', '_user'))\n",
        "    train['z_rating'] = (train['rating'] - train['mean']) / train['std']\n",
        "\n",
        "    # 4. Test도 동일한 통계량으로 변환 (Train에 없는 사용자는 제거 → cold-start 방지)\n",
        "    test = test.merge(user_stats, on='userId', how='left')\n",
        "    test = test.dropna(subset=['mean', 'std'])   # Train에 없는 사용자 제거\n",
        "    test['z_rating'] = (test['rating'] - test['mean']) / test['std']\n",
        "\n",
        "    return train, test, user_stats   # user_stats도 반환 (역변환에 필요)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 평가 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cd65a997",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def fast_predict_matrix_no_k(train_df):\n",
        "    \"\"\"\n",
        "    K 제한 없이, 유사도가 양수인 모든 아이템을 사용하여 예측\n",
        "    \"\"\"\n",
        "    # 1. Pivot Table 생성 및 R 행렬 정의\n",
        "    pivot_df = train_df.pivot(index='userId', columns='movieId', values='z_rating').fillna(0)\n",
        "    R = pivot_df.values  # (Users, Items)\n",
        "    user_ids = pivot_df.index\n",
        "    movie_ids = pivot_df.columns\n",
        "    \n",
        "    # 2. 아이템 간 유사도 행렬 계산\n",
        "    sim_matrix = np.dot(R.T, R)\n",
        "    np.fill_diagonal(sim_matrix, -np.inf)\n",
        "    \n",
        "    # 3. [핵심 변경] Top-K 필터링 로직 삭제! 양수 유사도만 남김\n",
        "    S = np.where(sim_matrix > 0, sim_matrix, 0)\n",
        "\n",
        "    # 4. 예측 평점 계산 (Weighted Sum) -> 분자\n",
        "    numerator = np.dot(R, S)\n",
        "    \n",
        "    # 5. 가중치 합 계산 (Sum of Weights) -> 분모\n",
        "    R_binary = (R != 0).astype(float)\n",
        "    denominator = np.dot(R_binary, np.abs(S))\n",
        "    \n",
        "    # 6. 나눗셈 (0으로 나누기 방지)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        pred_z = numerator / denominator\n",
        "        pred_z = np.nan_to_num(pred_z)\n",
        "        \n",
        "    return pred_z, user_ids, movie_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1fbc32fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel # Dot Product와 동일\n",
        "\n",
        "def fast_predict_matrix_with_tags(train_df, movie_tags_series, tag_weight=0.15):\n",
        "    \"\"\"\n",
        "    평점 기반 CF와 태그 기반 Content-based Filtering을 결합한 하이브리드 예측\n",
        "    \n",
        "    Args:\n",
        "        tag_weight (float): 태그 유사도의 반영 비율 (0.0 ~ 1.0)\n",
        "                            0.0이면 순수 CF, 1.0이면 순수 태그 추천\n",
        "    \"\"\"\n",
        "    # 1. Pivot Table 생성 및 R 행렬 정의 (Z-Score)\n",
        "    pivot_df = train_df.pivot(index='userId', columns='movieId', values='z_rating').fillna(0)\n",
        "    R = pivot_df.values\n",
        "    user_ids = pivot_df.index\n",
        "    movie_ids = pivot_df.columns # 현재 Train 셋에 존재하는 영화 ID 순서\n",
        "    \n",
        "    # -------------------------------------------------------\n",
        "    # [A] 평점 기반 유사도 (Collaborative Filtering) - Dot Product\n",
        "    # -------------------------------------------------------\n",
        "    sim_cf = np.dot(R.T, R)\n",
        "    \n",
        "    # -------------------------------------------------------\n",
        "    # [B] 태그 기반 유사도 (Content-Based) - Dot Product (Linear Kernel)\n",
        "    # -------------------------------------------------------\n",
        "    # 1. 현재 Train에 있는 영화 순서대로 태그 데이터 정렬 (없으면 빈 문자열)\n",
        "    current_movie_tags = [movie_tags_series.get(mid, \"\") for mid in movie_ids]\n",
        "    \n",
        "    # 2. TF-IDF 벡터화\n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=500)\n",
        "    tfidf_matrix = tfidf.fit_transform(current_movie_tags)\n",
        "    \n",
        "    # 3. 태그 유사도 계산 (Dot Product)\n",
        "    # TF-IDF 벡터는 정규화되어 있으므로 Dot Product는 코사인 유사도와 같음\n",
        "    sim_tags = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "    \n",
        "    # -------------------------------------------------------\n",
        "    # [C] 유사도 결합 (Hybrid) & 스케일 맞추기\n",
        "    # -------------------------------------------------------\n",
        "    # 평점 유사도(sim_cf)는 값이 크고(예: 수백), 태그 유사도(sim_tags)는 작음(0~1)\n",
        "    # 따라서 sim_cf를 최대값으로 나누어 -1 ~ 1 사이로 정규화한 뒤 결합\n",
        "    \n",
        "    max_cf = np.max(np.abs(sim_cf)) if np.max(np.abs(sim_cf)) > 0 else 1.0\n",
        "    sim_cf_norm = sim_cf / max_cf \n",
        "    \n",
        "    # 하이브리드 유사도 계산\n",
        "    # (1 - tag_weight) * 평점유사도 + (tag_weight) * 태그유사도\n",
        "    sim_hybrid = (1 - tag_weight) * sim_cf_norm + (tag_weight) * sim_tags\n",
        "    \n",
        "    # 자기 자신과의 유사도 제거\n",
        "    np.fill_diagonal(sim_hybrid, -np.inf)\n",
        "    \n",
        "    # 4. 양수 유사도만 남김 (K 제한 없음)\n",
        "    S = np.where(sim_hybrid > 0, sim_hybrid, 0)\n",
        "\n",
        "    # 5. 예측 평점 계산 (Weighted Sum)\n",
        "    numerator = np.dot(R, S)\n",
        "    \n",
        "    R_binary = (R != 0).astype(float)\n",
        "    denominator = np.dot(R_binary, np.abs(S))\n",
        "    \n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        pred_z = numerator / denominator\n",
        "        pred_z = np.nan_to_num(pred_z)\n",
        "        \n",
        "    return pred_z, user_ids, movie_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rmse(y_true, y_pred): return np.sqrt(np.mean((np.array(y_true)-np.array(y_pred))**2))\n",
        "def mae(y_true, y_pred):  return np.mean(np.abs(np.array(y_true)-np.array(y_pred)))\n",
        "\n",
        "def time_predictions(fn, pairs):\n",
        "    s = time.perf_counter()\n",
        "    preds = [fn(u,i) for u,i in pairs]\n",
        "    e = time.perf_counter() - s\n",
        "    return preds, e, (e/len(pairs))*1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Multi-seed 실험 루프"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "실험 시작: 태그 정보 결합 (가중치: 0.05)\n",
            "총 5개의 시드 테스트.\n",
            "\n",
            "Running Seed 10 (1/5)\n",
            " -> RMSE: 0.8560, Time: 9.3795s\n",
            "\n",
            "[추천 결과 생성 중...]\n",
            "\n",
            "Running Seed 21 (2/5)\n",
            " -> RMSE: 0.8642, Time: 7.8489s\n",
            "\n",
            "Running Seed 35 (3/5)\n",
            " -> RMSE: 0.8731, Time: 8.0815s\n",
            "\n",
            "Running Seed 42 (4/5)\n",
            " -> RMSE: 0.8905, Time: 6.5938s\n",
            "\n",
            "Running Seed 57 (5/5)\n",
            " -> RMSE: 0.8402, Time: 6.1086s\n",
            "\n",
            "실험 완료! (결과 요약 셀을 실행하세요)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# [3. Multi-seed 실험 루프 - 태그 결합 하이브리드 버전]\n",
        "# ==========================================\n",
        "\n",
        "results = []\n",
        "best_reco = None\n",
        "\n",
        "# 태그 가중치 설정 (0.1 ~ 0.3 정도 추천)\n",
        "TAG_WEIGHT = 0.05 \n",
        "\n",
        "print(f\"실험 시작: 태그 정보 결합 (가중치: {TAG_WEIGHT})\")\n",
        "print(f\"총 {len(SEED_LIST)}개의 시드 테스트.\")\n",
        "\n",
        "for idx, SEED in enumerate(SEED_LIST):\n",
        "    print(f\"\\nRunning Seed {SEED} ({idx+1}/{len(SEED_LIST)})\")\n",
        "\n",
        "    # 1. 데이터 분할 및 전처리\n",
        "    train_raw, test_raw = train_test_split(ratings, test_size=0.2, random_state=SEED)\n",
        "    train, test, user_stats = run_preprocessing(train_raw, test_raw)\n",
        "\n",
        "    # 2. [수정됨] 태그 정보를 포함한 하이브리드 예측 함수 호출\n",
        "    s = time.perf_counter()\n",
        "    # movie_tags_series는 1단계에서 만든 것을 전달\n",
        "    pred_matrix_z, u_ids, m_ids = fast_predict_matrix_with_tags(train, movie_tags_series, tag_weight=TAG_WEIGHT)\n",
        "    e = time.perf_counter() - s\n",
        "    \n",
        "    # 인덱싱 맵핑\n",
        "    u_map = {u: i for i, u in enumerate(u_ids)}\n",
        "    m_map = {m: i for i, m in enumerate(m_ids)}\n",
        "\n",
        "    # 3. Test 샘플링 (평가용 데이터 3000개)\n",
        "    rng = np.random.default_rng(SEED)\n",
        "    test_sample = test[['userId', 'movieId', 'rating', 'mean', 'std']].sample(n=min(3000, len(test)), random_state=SEED)\n",
        "\n",
        "    # 4. Test 데이터에 대한 예측값 추출\n",
        "    z_preds = []\n",
        "    for uid, mid in zip(test_sample['userId'], test_sample['movieId']):\n",
        "        if uid in u_map and mid in m_map:\n",
        "            u_idx = u_map[uid]\n",
        "            m_idx = m_map[mid]\n",
        "            z_preds.append(pred_matrix_z[u_idx, m_idx])\n",
        "        else:\n",
        "            z_preds.append(0.0)\n",
        "\n",
        "    # 5. 역변환\n",
        "    original_preds = []\n",
        "    for pred_z, row in zip(z_preds, test_sample.itertuples()):\n",
        "        mean_u = row.mean\n",
        "        std_u  = row.std\n",
        "        original_preds.append(pred_z * std_u + mean_u)\n",
        "\n",
        "    # 6. 결과 저장\n",
        "    avg_ms = (e / len(test_sample)) * 1000 \n",
        "    \n",
        "    res = {\n",
        "        'seed': SEED,\n",
        "        'rmse': rmse(test_sample['rating'], original_preds),\n",
        "        'mae' : mae(test_sample['rating'], original_preds),\n",
        "        'avg_ms': avg_ms\n",
        "    }\n",
        "    results.append(res)\n",
        "    print(f\" -> RMSE: {res['rmse']:.4f}, Time: {e:.4f}s\")\n",
        "\n",
        "    # 7. 첫 번째 시드(Seed 10)에서만 추천 결과 생성 (로직 동일)\n",
        "    if idx == 0:\n",
        "        def recommend(user_id, topk=3):\n",
        "            if user_id not in u_map: return None\n",
        "            u_idx = u_map[user_id]\n",
        "            user_row_preds = pred_matrix_z[u_idx] \n",
        "            watched = set(train[train['userId']==user_id]['movieId'])\n",
        "            \n",
        "            candidates = []\n",
        "            for m_idx, m_id in enumerate(m_ids):\n",
        "                if m_id in watched: continue\n",
        "                \n",
        "                z = user_row_preds[m_idx]\n",
        "                mean_u = user_stats.loc[user_id, 'mean']\n",
        "                std_u  = user_stats.loc[user_id, 'std']\n",
        "                final_score = z * std_u + mean_u\n",
        "                \n",
        "                candidates.append((m_id, final_score))\n",
        "            \n",
        "            candidates.sort(key=lambda x: -x[1])\n",
        "            top = candidates[:topk]\n",
        "            \n",
        "            return [{\n",
        "                'movieId': m,\n",
        "                'title': movies.loc[movies['movieId']==m, 'title'].iloc[0] if len(movies.loc[movies['movieId']==m]) > 0 else \"Unknown\",\n",
        "                'predicted_rating': round(score, 3)\n",
        "            } for m, score in top]\n",
        "\n",
        "        print(\"\\n[추천 결과 생성 중...]\")\n",
        "        best_reco = {\n",
        "            'heavy': recommend(PERSONA_HEAVY_USER),\n",
        "            'specialist': recommend(PERSONA_GENRE_SPECIALIST)\n",
        "        }\n",
        "\n",
        "print(\"\\n실험 완료! (결과 요약 셀을 실행하세요)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 결과 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   seed    rmse     mae  avg_ms\n",
            "0    10  0.8560  0.6449  3.1265\n",
            "1    21  0.8642  0.6568  2.6163\n",
            "2    35  0.8731  0.6637  2.6938\n",
            "3    42  0.8905  0.6719  2.1979\n",
            "4    57  0.8402  0.6408  2.0362\n",
            "\n",
            "=== 평균 ± 표준편차 ===\n",
            "RMSE : 0.8648 ± 0.0188\n",
            "MAE  : 0.6556 ± 0.0129\n",
            "예측 속도 : 2.53 ms (± 0.43)\n",
            "\n",
            "=== 페르소나 추천 결과 (Seed 10) ===\n",
            "헤비 유저 (userId=414)\n",
            "  → Harmonists, The (1997)  (예측 평점 5.0)\n",
            "  → Taxi 3 (2003)  (예측 평점 4.945)\n",
            "  → The Red Turtle (2016)  (예측 평점 4.804)\n",
            "\n",
            "드라마 전문가 (userId=85)\n",
            "  → Mr. Wrong (1996)  (예측 평점 5.0)\n",
            "  → Before and After (1996)  (예측 평점 5.0)\n",
            "  → Awfully Big Adventure, An (1995)  (예측 평점 5.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(results)\n",
        "print(df[['seed','rmse','mae','avg_ms']].round(4))\n",
        "print(\"\\n=== 평균 ± 표준편차 ===\")\n",
        "print(f\"RMSE : {df.rmse.mean():.4f} ± {df.rmse.std():.4f}\")\n",
        "print(f\"MAE  : {df.mae.mean():.4f} ± {df.mae.std():.4f}\")\n",
        "print(f\"예측 속도 : {df.avg_ms.mean():.2f} ms (± {df.avg_ms.std():.2f})\")\n",
        "\n",
        "print(\"\\n=== 페르소나 추천 결과 (Seed 10) ===\")\n",
        "print(f\"헤비 유저 (userId={PERSONA_HEAVY_USER})\")\n",
        "for x in best_reco['heavy']:\n",
        "    print(f\"  → {x['title']}  (예측 평점 {x['predicted_rating']})\")\n",
        "\n",
        "print(f\"\\n드라마 전문가 (userId={PERSONA_GENRE_SPECIALIST})\")\n",
        "for x in best_reco['specialist']:\n",
        "    print(f\"  → {x['title']}  (예측 평점 {x['predicted_rating']})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "67fbc37b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Grid Search 시작 ===\n",
            "\n",
            "[Testing] max_features = 500 ...\n",
            "   -> Weight: 0.05 | RMSE: 0.8843 | Time: 10.84s\n",
            "   -> Weight: 0.1 | RMSE: 0.8853 | Time: 9.89s\n",
            "   -> Weight: 0.15 | RMSE: 0.8863 | Time: 8.27s\n",
            "   -> Weight: 0.2 | RMSE: 0.8875 | Time: 8.10s\n",
            "   -> Weight: 0.25 | RMSE: 0.8888 | Time: 7.94s\n",
            "\n",
            "[Testing] max_features = 1000 ...\n",
            "   -> Weight: 0.05 | RMSE: 0.8844 | Time: 8.03s\n",
            "   -> Weight: 0.1 | RMSE: 0.8853 | Time: 9.86s\n",
            "   -> Weight: 0.15 | RMSE: 0.8863 | Time: 8.76s\n",
            "   -> Weight: 0.2 | RMSE: 0.8874 | Time: 9.99s\n",
            "   -> Weight: 0.25 | RMSE: 0.8886 | Time: 10.01s\n",
            "\n",
            "[Testing] max_features = 3000 ...\n",
            "   -> Weight: 0.05 | RMSE: 0.8845 | Time: 9.50s\n",
            "   -> Weight: 0.1 | RMSE: 0.8853 | Time: 9.36s\n",
            "   -> Weight: 0.15 | RMSE: 0.8862 | Time: 8.29s\n",
            "   -> Weight: 0.2 | RMSE: 0.8873 | Time: 8.62s\n",
            "   -> Weight: 0.25 | RMSE: 0.8885 | Time: 11.92s\n",
            "\n",
            "=== 최적의 파라미터 조합 ===\n",
            "Max Features: 500\n",
            "Tag Weight  : 0.05\n",
            "Best RMSE   : 0.8843\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# [Grid Search] 최적의 파라미터(태그 가중치, 개수) 찾기\n",
        "# ==========================================\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import time\n",
        "\n",
        "# 1. 테스트할 파라미터 후보군 정의\n",
        "MAX_FEATURES_LIST = [500, 1000, 3000]   # 태그 개수 후보\n",
        "TAG_WEIGHT_LIST   = [0.05, 0.1, 0.15, 0.2, 0.25] # 가중치 후보\n",
        "\n",
        "# 결과 저장용\n",
        "grid_results = []\n",
        "\n",
        "print(\"=== Grid Search 시작 ===\")\n",
        "\n",
        "# Train/Test 데이터는 고정된 시드(예: 42)로 한 번만 나눔 (비교를 위해)\n",
        "FIXED_SEED = 42\n",
        "train_raw, test_raw = train_test_split(ratings, test_size=0.2, random_state=FIXED_SEED)\n",
        "train, test, user_stats = run_preprocessing(train_raw, test_raw)\n",
        "\n",
        "# [A] max_features 루프\n",
        "for n_feat in MAX_FEATURES_LIST:\n",
        "    print(f\"\\n[Testing] max_features = {n_feat} ...\")\n",
        "    \n",
        "    # 1. TF-IDF 및 태그 유사도 계산 (n_feat가 바뀔 때마다 새로 계산)\n",
        "    # 현재 Train에 있는 영화 ID 기준 태그 정렬\n",
        "    pivot_temp = train.pivot(index='userId', columns='movieId', values='z_rating').fillna(0)\n",
        "    movie_ids_temp = pivot_temp.columns\n",
        "    current_movie_tags = [movie_tags_series.get(mid, \"\") for mid in movie_ids_temp]\n",
        "    \n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=n_feat)\n",
        "    tfidf_matrix = tfidf.fit_transform(current_movie_tags)\n",
        "    sim_tags_fixed = linear_kernel(tfidf_matrix, tfidf_matrix) # 미리 계산\n",
        "    \n",
        "    # [B] tag_weight 루프\n",
        "    for weight in TAG_WEIGHT_LIST:\n",
        "        \n",
        "        # --- 예측 로직 (Inline 구현) ---\n",
        "        s_time = time.perf_counter()\n",
        "        \n",
        "        # 평점 유사도\n",
        "        R = pivot_temp.values\n",
        "        sim_cf = np.dot(R.T, R)\n",
        "        max_cf = np.max(np.abs(sim_cf)) if np.max(np.abs(sim_cf)) > 0 else 1.0\n",
        "        sim_cf_norm = sim_cf / max_cf\n",
        "        \n",
        "        # 하이브리드 결합\n",
        "        sim_hybrid = (1 - weight) * sim_cf_norm + (weight) * sim_tags_fixed\n",
        "        np.fill_diagonal(sim_hybrid, -np.inf)\n",
        "        \n",
        "        # 예측 계산\n",
        "        S = np.where(sim_hybrid > 0, sim_hybrid, 0)\n",
        "        num = np.dot(R, S)\n",
        "        den = np.dot((R != 0).astype(float), np.abs(S))\n",
        "        \n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            pred_z = np.nan_to_num(num / den)\n",
        "            \n",
        "        # 평가 (Test Sample 3000개)\n",
        "        rng = np.random.default_rng(FIXED_SEED)\n",
        "        test_sample = test.sample(n=min(3000, len(test)), random_state=FIXED_SEED)\n",
        "        \n",
        "        u_map = {u: i for i, u in enumerate(pivot_temp.index)}\n",
        "        m_map = {m: i for i, m in enumerate(pivot_temp.columns)}\n",
        "        \n",
        "        original_preds = []\n",
        "        y_true = []\n",
        "        \n",
        "        for row in test_sample.itertuples():\n",
        "            if row.userId in u_map and row.movieId in m_map:\n",
        "                u_idx = u_map[row.userId]\n",
        "                m_idx = m_map[row.movieId]\n",
        "                val = pred_z[u_idx, m_idx]\n",
        "                original_preds.append(val * row.std + row.mean)\n",
        "                y_true.append(row.rating)\n",
        "        \n",
        "        curr_rmse = rmse(y_true, original_preds)\n",
        "        e_time = time.perf_counter() - s_time\n",
        "        \n",
        "        print(f\"   -> Weight: {weight} | RMSE: {curr_rmse:.4f} | Time: {e_time:.2f}s\")\n",
        "        \n",
        "        grid_results.append({\n",
        "            'max_features': n_feat,\n",
        "            'tag_weight': weight,\n",
        "            'rmse': curr_rmse\n",
        "        })\n",
        "\n",
        "# 3. 최적의 결과 출력\n",
        "df_grid = pd.DataFrame(grid_results)\n",
        "best_row = df_grid.loc[df_grid['rmse'].idxmin()]\n",
        "\n",
        "print(\"\\n=== 최적의 파라미터 조합 ===\")\n",
        "print(f\"Max Features: {int(best_row['max_features'])}\")\n",
        "print(f\"Tag Weight  : {best_row['tag_weight']}\")\n",
        "print(f\"Best RMSE   : {best_row['rmse']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a81518",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": "MovieLens 100K + Item-based CF + Z-Score (올바르게 적용된 버전)",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
